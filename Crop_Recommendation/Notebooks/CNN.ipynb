{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "model_name = \"CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"Data_Processed/Recommendation.csv\")\n",
    "df = pd.read_csv(\"../Data/Crop_production 2.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Unnamed: 0\"],axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.columns:\n",
    "#     print(i,df[i].unique(),df[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_info(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    outlier_count = outliers.shape[0]\n",
    "    total_count = df.shape[0]\n",
    "    outlier_percentage = (outlier_count / total_count) * 100\n",
    "\n",
    "    return outlier_count, outlier_percentage\n",
    "\n",
    "def outlier_remover(df,column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    df.loc[df[column] < lower_bound, column] = lower_bound\n",
    "    df.loc[df[column] > upper_bound, column] = upper_bound\n",
    "    return df\n",
    "# for i in df.columns:\n",
    "#     if df[i].dtype != \"object\":\n",
    "#         sns.boxplot(df[i])\n",
    "#         plt.show()\n",
    "#         print(f\"Outlier counter and percentage for {i}: {outlier_info(df, i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Area_in_hectares\"] = np.log(df[\"Area_in_hectares\"])\n",
    "df[\"Production_in_tons\"] = np.log(df[\"Production_in_tons\"])\n",
    "df[\"Yield_ton_per_hec\"] = np.log(df[\"Yield_ton_per_hec\"])\n",
    "\n",
    "\n",
    "df = outlier_remover(df,\"N\")\n",
    "df = outlier_remover(df,\"P\")\n",
    "df = outlier_remover(df,\"K\")\n",
    "df = outlier_remover(df,\"pH\")\n",
    "df = outlier_remover(df,\"rainfall\")\n",
    "df = outlier_remover(df,\"temperature\")\n",
    "df = outlier_remover(df,\"Area_in_hectares\")\n",
    "df = outlier_remover(df,\"Production_in_tons\")\n",
    "df = outlier_remover(df,\"Yield_ton_per_hec\")\n",
    "\n",
    "# for i in df.columns:\n",
    "#     if df[i].dtype != \"object\":\n",
    "#         sns.boxplot(df[i])\n",
    "#         plt.show()\n",
    "#         print(f\"Outlier counter and percentage for {i}: {outlier_info(df, i)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the class distribution\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.countplot(x=df['Crop'])\n",
    "# plt.title('Class Distribution of Crop')\n",
    "# plt.xlabel('Crop')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = df[\"Crop\"].value_counts()\n",
    "# print(tt)\n",
    "df = df[df[\"Crop\"] != \"apple\"]\n",
    "df = df[df[\"Crop\"] != \"coffee\"]\n",
    "tt = df[\"Crop\"].value_counts()\n",
    "# print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "C = [\"State_Name\",\"Crop_Type\",\"Crop\"]\n",
    "le_D = {}\n",
    "for i in C:\n",
    "    le_D[i] = LabelEncoder()\n",
    "    df[i] = le_D[i].fit_transform(df[i])\n",
    "\n",
    "bulk_scaler = StandardScaler()\n",
    "features_to_scale = [\"State_Name\",\"Crop_Type\",\"N\",\"P\",\"K\",\"pH\",\"rainfall\",\"temperature\",\"Area_in_hectares\",\"Production_in_tons\",\"Yield_ton_per_hec\"]\n",
    "#features_to_scale = [\"N\",\"P\",\"K\",\"pH\",\"rainfall\",\"temperature\",\"Area_in_hectares\",\"Yield_ton_per_hec\"]\n",
    "df[features_to_scale] = bulk_scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "df.info()\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "t = df[[\"Production_in_tons\",\"Area_in_hectares\"]].values\n",
    "pca = PCA(n_components=1)\n",
    "X_pca = pca.fit_transform(t)\n",
    "\n",
    "df = df.drop([\"Production_in_tons\",\"Area_in_hectares\",\"Yield_ton_per_hec\"],axis=1)\n",
    "df[\"PCA\"] = X_pca\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split,TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import *\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropRecommendationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(CropRecommendationModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(128 * input_size, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) \n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA,IncrementalPCA\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve,precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "#import shap\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.calibration import calibration_curve\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "def plot_tsne_pca(features, targets, target_names,name,sample_size=2000):\n",
    "    # Subsample the data for faster computation\n",
    "    if len(features) > sample_size:\n",
    "        idx = np.random.choice(len(features), sample_size, replace=False)\n",
    "        features_sampled = features[idx]\n",
    "        targets_sampled = targets[idx]\n",
    "    else:\n",
    "        features_sampled = features\n",
    "        targets_sampled = targets\n",
    "\n",
    "    # TSNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, n_jobs=-1)\n",
    "    tsne_results = tsne.fit_transform(features_sampled)\n",
    "    \n",
    "    for i, target_name in enumerate(target_names):\n",
    "        plt.scatter(tsne_results[targets_sampled == i, 0], tsne_results[targets_sampled == i, 1], label=le_D[\"Crop\"].inverse_transform([target_name])[0], s=10)\n",
    "    plt.title(\"t-SNE\")\n",
    "    plt.grid()\n",
    "    #plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    # plt.show()\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.savefig(f'../Results/{name}_tsne.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    fig_legend = plt.figure(figsize=(10, 10))\n",
    "    legend = plt.figlegend(handles, labels, loc='center', ncol=10)\n",
    "    for label in legend.get_texts():\n",
    "        label.set_ha('right')\n",
    "    fig_legend.savefig(f'../Results/{name}_tsne_legend.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(f'../Results/{name}_tsne.png'))\n",
    "    display(Image(f'../Results/{name}_tsne_legend.png'))\n",
    "    \n",
    "    # PCA\n",
    "    pca = IncrementalPCA(n_components=2)\n",
    "    pca_results = pca.fit_transform(features_sampled)\n",
    "    \n",
    "    for i, target_name in enumerate(target_names):\n",
    "        plt.scatter(pca_results[targets_sampled == i, 0], pca_results[targets_sampled == i, 1], label=le_D[\"Crop\"].inverse_transform([target_name])[0], s=10)\n",
    "    plt.title(\"PCA\")\n",
    "    plt.grid()\n",
    "    # plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    # plt.show()\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.savefig(f'../Results/{name}_pca.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    fig_legend = plt.figure(figsize=(10, 10))\n",
    "    legend = plt.figlegend(handles, labels, loc='center', ncol=10)\n",
    "    for label in legend.get_texts():\n",
    "        label.set_ha('right')\n",
    "    fig_legend.savefig(f'../Results/{name}_pca_legend.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(f'../Results/{name}_pca.png'))\n",
    "    display(Image(f'../Results/{name}_pca_legend.png'))\n",
    "\n",
    "def plot_radar_chart(metrics_df,name):\n",
    "    labels = metrics_df['Class']\n",
    "    num_vars = len(labels)\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "    ax.set_theta_offset(np.pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    for metric in metrics_df.columns[1:]:\n",
    "        values = metrics_df[metric].tolist()\n",
    "        values += values[:1]\n",
    "        ax.plot(angles, values, label=metric)\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    plt.title('Metrics Radar Chart')\n",
    "    plt.savefig(f\"../Results/{name}_radar_chart.png\")\n",
    "    plt.show()\n",
    "    \n",
    "def compute_metrics(val_target, val_predicted, num_classes):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(val_target, val_predicted, average=None, labels=range(num_classes),zero_division=1)\n",
    "    metrics = {\n",
    "        'Class': range(num_classes),\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "def train_validation(train_features, test_features, train_target, test_target,name,num_epochs=100,learning_rate=0.001):\n",
    "\n",
    "    input_size = train_features.shape[1]\n",
    "    hidden_size = 64\n",
    "    num_classes = len(data['Crop'].unique())\n",
    "\n",
    "    model = CropRecommendationModel(input_size, hidden_size, num_classes).to(\"cuda\")\n",
    "    #model = torch.compile(model)\n",
    "    # num_epochs = 1100\n",
    "    #learning_rate = 0.001\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        outputs = model(train_features)\n",
    "        loss = criterion(outputs, train_target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, train_predicted = torch.max(outputs.data, 1)\n",
    "            train_correct = (train_predicted == train_target).sum().item()\n",
    "            train_accuracy = train_correct / train_target.size(0)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(test_features)\n",
    "            test_loss = criterion(test_outputs, test_target)\n",
    "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "            test_correct = (test_predicted == test_target).sum().item()\n",
    "            test_accuracy = test_correct / test_target.size(0)\n",
    "            test_losses.append(test_loss.item())\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Plotting all graphs in a single figure\n",
    "    \n",
    "    # Loss and Accuracy Graphs\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(num_epochs), train_losses, label='Train Loss', color=\"orange\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Epoch vs Loss Plot\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(num_epochs), test_losses, label='Val Loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation Epoch vs Loss Plot\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'../Results/{name}_loss_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(num_epochs), train_accuracies, label='Train Accuracy', color=\"orange\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training Epoch vs Accuracy Plot\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(num_epochs), test_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Validation Epoch vs Accuracy Plot\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f'../Results/{name}_accu_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_features)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "    \n",
    "    test_predicted_names = le_D[\"Crop\"].inverse_transform(test_predicted.cpu())\n",
    "    test_target_names = le_D[\"Crop\"].inverse_transform(test_target.cpu())\n",
    "    cm = confusion_matrix(test_target_names, test_predicted_names)\n",
    "    colors = [\"#000000\", \"#ff0000\"]  # Black and Red\n",
    "    cmap = sns.color_palette(colors)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, cbar=False, linewidths=0.5, linecolor='white')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'../Results/{name}_cm_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(test_features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = (predicted == test_target).sum().item() / test_target.size(0)\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "    all_metrics = []\n",
    "    fold_metrics = compute_metrics(test_target.cpu().numpy(), test_predicted.cpu().numpy(), num_classes)\n",
    "    all_metrics.append(fold_metrics)\n",
    "    avg_metrics = pd.concat(all_metrics).groupby('Class').mean().reset_index()\n",
    "    avg_metrics['Class'] = le_D['Crop'].inverse_transform(avg_metrics['Class'].astype(int))\n",
    "    plot_radar_chart(avg_metrics,name)\n",
    "    \n",
    "    val_target_onehot = nn.functional.one_hot(test_target, num_classes=num_classes).cpu().numpy()\n",
    "    roc_auc_dict = {}\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        fpr, tpr, _ = roc_curve(val_target_onehot[:, i], test_outputs.cpu().numpy()[:, i])\n",
    "        roc_auc_dict[i] = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'Class {le_D[\"Crop\"].inverse_transform([i])[0]} (area = {roc_auc_dict[i]:0.2f})')\n",
    "\n",
    "    # Plot diagonal line\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.grid()\n",
    "\n",
    "    # Capture the legend handles and labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "    # Save the ROC curve plot without the legend\n",
    "    plt.savefig(f'../Results/{name}_roc_curve.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Create a new figure for the legend\n",
    "    fig_legend = plt.figure(figsize=(8, 6))\n",
    "    plt.axis('off')\n",
    "    legend = plt.figlegend(handles, labels, loc='center', ncol=5)\n",
    "    for label in legend.get_texts():\n",
    "        label.set_ha('right')\n",
    "    fig_legend.savefig(f'../Results/{name}_roc_curve_legend.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # Show ROC curve and legend separately\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(f'../Results/{name}_roc_curve.png'))\n",
    "    display(Image(f'../Results/{name}_roc_curve_legend.png'))\n",
    "\n",
    "\n",
    "    plot_tsne_pca(train_features.cpu(), train_target.cpu(), target_names=data['Crop'].unique(),name=name)\n",
    "    return model, criterion\n",
    "\n",
    "def cross_check(features, target, name, k=10, num_epochs=100,learning_rate=0.001):\n",
    "    #learning_rate = 0.001\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(features)):\n",
    "        train_features, val_features = features[train_idx], features[val_idx]\n",
    "        train_target, val_target = target[train_idx], target[val_idx]\n",
    "        input_size = train_features.shape[1]\n",
    "        hidden_size = 64\n",
    "        num_classes = len(data['Crop'].unique())\n",
    "\n",
    "        model = CropRecommendationModel(input_size, hidden_size, num_classes).to(\"cuda\")\n",
    "        #model = torch.compile(model)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        xt = []\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            outputs = model(train_features)\n",
    "            loss = criterion(outputs, train_target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            xt.append(epoch)\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(val_features)\n",
    "                val_loss = criterion(val_outputs, val_target)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "        if fold == 0:\n",
    "            xt = np.array(xt)\n",
    "            train_losses = np.array(train_losses)\n",
    "            val_losses = np.array(val_losses)\n",
    "            plt.plot(xt, train_losses, label='Train Loss')\n",
    "            plt.plot(xt, val_losses, label='Validation Loss')\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.grid()\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Epoch vs Loss Plot for Fold 1\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            print(f'Epoch [{xt[-1]+1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_outputs = model(train_features)\n",
    "            train_loss = criterion(train_outputs, train_target)\n",
    "            _, train_predicted = torch.max(train_outputs.data, 1)\n",
    "            train_correct = (train_predicted == train_target).sum().item()\n",
    "            train_accuracy = train_correct / train_target.size(0)\n",
    "\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = criterion(val_outputs, val_target)\n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_correct = (val_predicted == val_target).sum().item()\n",
    "            val_accuracy = val_correct / val_target.size(0)\n",
    "\n",
    "            # Compute additional metrics\n",
    "            train_precision = precision_score(train_target.cpu(), train_predicted.cpu(), average='weighted',zero_division=0)\n",
    "            train_recall = recall_score(train_target.cpu(), train_predicted.cpu(), average='weighted',zero_division=0)\n",
    "            #train_recall_ng = recall_score(train_target.cpu(), train_predicted.cpu(), average='weighted',zero_division=0,pos_label=0)\n",
    "            train_f1 = f1_score(train_target.cpu(), train_predicted.cpu(), average='weighted',zero_division=0)\n",
    "\n",
    "            val_precision = precision_score(val_target.cpu(), val_predicted.cpu(), average='weighted',zero_division=0)\n",
    "            val_recall = recall_score(val_target.cpu(), val_predicted.cpu(), average='weighted',zero_division=0)\n",
    "            #val_recall_ng = recall_score(val_target.cpu(), val_predicted.cpu(), average='weighted',zero_division=0,pos_label=0)\n",
    "            val_f1 = f1_score(val_target.cpu(), val_predicted.cpu(), average='weighted',zero_division=0)\n",
    "            \n",
    "            conf_mat_train = confusion_matrix(train_target.cpu(), train_predicted.cpu())\n",
    "            conf_mat_val = confusion_matrix(val_target.cpu(), val_predicted.cpu())\n",
    "            tnr_per_class_train = []\n",
    "            tnr_per_class_val = []\n",
    "            for i in range(len(conf_mat_train)):\n",
    "                tn = np.sum(np.delete(np.delete(conf_mat_train, i, axis=0), i, axis=1))\n",
    "                fp = np.sum(np.delete(conf_mat_train[:, i], i))\n",
    "                tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                tnr_per_class_train.append(tnr)\n",
    "            for i in range(len(conf_mat_val)):\n",
    "                tn = np.sum(np.delete(np.delete(conf_mat_val, i, axis=0), i, axis=1))\n",
    "                fp = np.sum(np.delete(conf_mat_val[:, i], i))\n",
    "                tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "                tnr_per_class_val.append(tnr)\n",
    "            \n",
    "            train_tnr = np.mean(tnr_per_class_train)\n",
    "            val_tnr = np.mean(tnr_per_class_val)\n",
    "            \n",
    "        fold_results.append({\n",
    "            'fold': fold+1,\n",
    "            'train_loss': train_loss.item(),\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_loss': val_loss.item(),\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'train_precision': train_precision,\n",
    "            'train_recall': train_recall,\n",
    "            'train_tnr': train_tnr,\n",
    "            'train_f1': train_f1,\n",
    "            'val_precision': val_precision,\n",
    "            'val_recall': val_recall,\n",
    "            'val_tnr': val_tnr,\n",
    "            'val_f1': val_f1\n",
    "        })\n",
    "        print(f'Fold {fold+1}, Train Loss: {train_loss.item()}, Train Accuracy: {train_accuracy*100:.2f}%, Validation Loss: {val_loss.item()}, Validation Accuracy: {val_accuracy*100:.2f}%')\n",
    "        print(f'Fold {fold+1}, Train Precision: {train_precision:.4f}, Train Recall: {train_recall:.4f},Train Negative Rate: {train_tnr:.4f} ,Train F1: {train_f1:.4f}')\n",
    "        print(f'Fold {fold+1}, Validation Precision: {val_precision:.4f}, Validation Recall: {val_recall:.4f},Validation Negative Rate: {val_tnr:.4f} ,Validation F1: {val_f1:.4f}')\n",
    "\n",
    "    # Visualization of k-fold cross-validation results\n",
    "    train_losses = [result['train_loss'] for result in fold_results]\n",
    "    val_losses = [result['val_loss'] for result in fold_results]\n",
    "    train_accuracies = [result['train_accuracy'] for result in fold_results]\n",
    "    val_accuracies = [result['val_accuracy'] for result in fold_results]\n",
    "    train_precisions = [result['train_precision'] for result in fold_results]\n",
    "    val_precisions = [result['val_precision'] for result in fold_results]\n",
    "    train_recalls = [result['train_recall'] for result in fold_results]\n",
    "    val_recalls = [result['val_recall'] for result in fold_results]\n",
    "    train_f1s = [result['train_f1'] for result in fold_results]\n",
    "    val_f1s = [result['val_f1'] for result in fold_results]\n",
    "    train_tnrs = [result['train_tnr'] for result in fold_results]\n",
    "    val_tnrs = [result['val_tnr'] for result in fold_results]\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    avg_train_accuracy = np.mean(train_accuracies)\n",
    "    avg_val_accuracy = np.mean(val_accuracies)\n",
    "    avg_train_precision = np.mean(train_precisions)\n",
    "    avg_val_precision = np.mean(val_precisions)\n",
    "    avg_train_recall = np.mean(train_recalls)\n",
    "    avg_val_recall = np.mean(val_recalls)\n",
    "    avg_train_f1 = np.mean(train_f1s)\n",
    "    avg_val_f1 = np.mean(val_f1s)\n",
    "    avg_train_tnr = np.mean(train_tnrs)\n",
    "    avg_val_tnr = np.mean(val_tnrs)\n",
    "    \n",
    "    avg_results = {\n",
    "            'fold': \"Average\",\n",
    "            'train_loss': avg_train_loss,\n",
    "            'train_accuracy': avg_train_accuracy,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_accuracy': avg_val_accuracy,\n",
    "            'train_precision': avg_train_precision,\n",
    "            'train_recall': avg_train_recall,\n",
    "            'train_tnr': avg_train_tnr,\n",
    "            'train_f1': avg_train_f1,\n",
    "            'val_precision': avg_val_precision,\n",
    "            'val_recall': avg_val_recall,\n",
    "            'val_tnr': avg_val_tnr,\n",
    "            'val_f1': avg_val_f1\n",
    "        }\n",
    "    \n",
    "    fold_results.append(avg_results)\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "    def smooth_curve(x, y):\n",
    "        x_smooth = np.linspace(min(x), max(x), 300)\n",
    "        spl = make_interp_spline(x, y, k=3)\n",
    "        y_smooth = spl(x_smooth)\n",
    "        return x_smooth, y_smooth\n",
    "\n",
    "    plt.figure(figsize=(20, 16))\n",
    "\n",
    "    # Plotting losses for each fold\n",
    "    plt.subplot(6, 1, 1)\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), train_losses)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='b', label='Train Loss')\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), val_losses)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='r', label='Validation Loss')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss per Fold\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting accuracies for each fold\n",
    "    plt.subplot(6, 1, 2)\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), train_accuracies)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='b', label='Train Accuracy')\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), val_accuracies)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='r', label='Validation Accuracy')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy per Fold\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting precision for each fol6\n",
    "    plt.subplot(6, 1, 3)\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), train_precisions)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='b', label='Train Precision')\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), val_precisions)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='r', label='Validation Precision')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision per Fold\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting recall for each fold\n",
    "    plt.subplot(6, 1, 4)\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), train_recalls)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='b', label='Train Recall')\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), val_recalls)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='r', label='Validation Recall')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.title(\"Recall per Fold\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(6, 1, 5)\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), train_tnrs)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='b', label='Train Negative Rate')\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), val_tnrs)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='r', label='Validation Negative Rate')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.title(\"Recall per Fold\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    # Plotting F1 score for each fold\n",
    "    plt.subplot(6, 1, 6)\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), train_f1s)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='b', label='Train F1')\n",
    "    x_smooth, y_smooth = smooth_curve(range(1, k + 1), val_f1s)\n",
    "    plt.plot(x_smooth, y_smooth, marker='', linestyle='-', color='r', label='Validation F1')\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"F1 Score per Fold\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../Results/{name}_Xvalidation_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    print(f'Average Train Loss: {avg_train_loss:.4f}')\n",
    "    print(f'Average Validation Loss: {avg_val_loss:.4f}')\n",
    "    print(f'Average Train Accuracy: {avg_train_accuracy:.4f}')\n",
    "    print(f'Average Validation Accuracy: {avg_val_accuracy:.4f}')\n",
    "    print(f'Average Train Precision: {avg_train_precision:.4f}')\n",
    "    print(f'Average Validation Precision: {avg_val_precision:.4f}')\n",
    "    print(f'Average Train Recall: {avg_train_recall:.4f}')\n",
    "    print(f'Average Validation Recall: {avg_val_recall:.4f}')\n",
    "    print(f'Average Train Negative Rate: {avg_train_tnr:.4f}')\n",
    "    print(f'Average Validation Negative Rate: {avg_val_tnr:.4f}')\n",
    "    print(f'Average Train F1: {avg_train_f1:.4f}')\n",
    "    print(f'Average Validation F1: {avg_val_f1:.4f}')\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswarm import pso\n",
    "\n",
    "# Store the history of PSO\n",
    "pso_history = []\n",
    "\n",
    "# Define the fitness function with logging for visualization\n",
    "def fitness_function(params, train_features, test_features, train_target, test_target):\n",
    "    global pso_history  # To store history\n",
    "    \n",
    "    # Extract the hyperparameters\n",
    "    num_epochs = int(params[0])\n",
    "    learning_rate = params[1]\n",
    "\n",
    "    # Define the model\n",
    "    input_size = train_features.shape[1]\n",
    "    hidden_size = 64\n",
    "    num_classes = len(train_target.unique())\n",
    "\n",
    "    model = CropRecommendationModel(input_size, hidden_size, num_classes).to(\"cuda\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training and Validation loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(train_features)\n",
    "        loss = criterion(outputs, train_target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_features)\n",
    "        test_loss = criterion(test_outputs, test_target)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_correct = (test_predicted == test_target).sum().item()\n",
    "        test_accuracy = test_correct / test_target.size(0)\n",
    "\n",
    "    # Store the current state\n",
    "    pso_history.append({\n",
    "        'num_epochs': num_epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'test_accuracy': test_accuracy\n",
    "    })\n",
    "\n",
    "    return -test_accuracy  # Since we want to maximize accuracy, minimize negative accuracy\n",
    "\n",
    "# PSO wrapper function\n",
    "def pso_optimize(train_features, test_features, train_target, test_target, lb, ub, num_particles=10, maxiter=20):\n",
    "    global pso_history\n",
    "    pso_history = []  # Reset history\n",
    "\n",
    "    # Run PSO\n",
    "    optimal_params, optimal_val = pso(\n",
    "        fitness_function,\n",
    "        lb,\n",
    "        ub,\n",
    "        args=(train_features, test_features, train_target, test_target),\n",
    "        swarmsize=num_particles,\n",
    "        maxiter=maxiter\n",
    "    )\n",
    "\n",
    "    optimal_num_epochs = int(optimal_params[0])\n",
    "    optimal_learning_rate = optimal_params[1]\n",
    "\n",
    "    print(f\"Optimal num_epochs: {optimal_num_epochs}\")\n",
    "    print(f\"Optimal learning_rate: {optimal_learning_rate}\")\n",
    "    print(f\"Optimal validation accuracy: {-optimal_val}\")\n",
    "\n",
    "    # Visualization\n",
    "    visualize_pso_history(pso_history)\n",
    "\n",
    "    return optimal_num_epochs, optimal_learning_rate\n",
    "\n",
    "# Function to visualize the PSO history\n",
    "def visualize_pso_history(history):\n",
    "    # Convert history to a DataFrame for easier plotting\n",
    "    import pandas as pd\n",
    "    history_df = pd.DataFrame(history)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.grid(True)\n",
    "    # Plot validation accuracy over iterations\n",
    "    sns.lineplot(data=history_df, x=history_df.index, y=\"test_accuracy\", marker=\"o\")\n",
    "    plt.title(\"PSO Optimization Progress\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Validation Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the evolution of num_epochs and learning_rate\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    sns.lineplot(data=history_df, x=history_df.index, y=\"num_epochs\", marker=\"o\", ax=axes[0])\n",
    "    axes[0].set_title(\"Evolution of num_epochs\")\n",
    "    axes[0].set_xlabel(\"Iteration\")\n",
    "    axes[0].set_ylabel(\"num_epochs\")\n",
    "\n",
    "    sns.lineplot(data=history_df, x=history_df.index, y=\"learning_rate\", marker=\"o\", ax=axes[1])\n",
    "    axes[1].set_title(\"Evolution of learning_rate\")\n",
    "    axes[1].set_xlabel(\"Iteration\")\n",
    "    axes[1].set_ylabel(\"learning_rate\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Define the bounds for the hyperparameters\n",
    "lb = [100, 0.001]  # Lower bounds: [num_epochs, learning_rate]\n",
    "ub = [2000, 0.01]  # Upper bounds: [num_epochs, learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def objective(params):\n",
    "    num_epochs = int(params['num_epochs'])\n",
    "    learning_rate = params['learning_rate']\n",
    "    \n",
    "    # Define the model\n",
    "    input_size = train_features.shape[1]\n",
    "    hidden_size = 64\n",
    "    num_classes = len(train_target.unique())\n",
    "\n",
    "    model = CropRecommendationModel(input_size, hidden_size, num_classes).to(\"cuda\")\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(train_features)\n",
    "        loss = criterion(outputs, train_target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(test_features)\n",
    "        _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "        test_correct = (test_predicted == test_target).sum().item()\n",
    "        test_accuracy = test_correct / test_target.size(0)\n",
    "    \n",
    "    # Since we want to maximize accuracy, we return negative accuracy for minimization\n",
    "    return {'loss': -test_accuracy, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'num_epochs': scope.int(hp.quniform('num_epochs', 10, 100, 10)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -2)\n",
    "}\n",
    "\n",
    "\n",
    "# Run the TPE optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek,SMOTEENN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = data.drop(columns=['Crop']).values\n",
    "target = data['Crop'].values\n",
    "\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).float().to(\"cuda\")\n",
    "target = torch.tensor(target, dtype=torch.long).long().to(\"cuda\")\n",
    "name = f\"{model_name}_Simple\"\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# optimal_num_epochs, optimal_learning_rate = pso_optimize(\n",
    "#     train_features, \n",
    "#     test_features, \n",
    "#     train_target, \n",
    "#     test_target, \n",
    "#     lb, \n",
    "#     ub,\n",
    "#     num_particles=10,\n",
    "#     maxiter=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('hyperopt.tpe').setLevel(logging.ERROR)\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    verbose=True,\n",
    "    rstate=np.random.default_rng(),\n",
    "    show_progressbar=True,\n",
    "    return_argmin=False,\n",
    ")\n",
    "print(\"Best hyperparameters found:\", best)\n",
    "\n",
    "# Convert trials to a pandas DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame({\n",
    "    'num_epochs': [trial['misc']['vals']['num_epochs'][0] for trial in trials.trials],\n",
    "    'learning_rate': [trial['misc']['vals']['learning_rate'][0] for trial in trials.trials],\n",
    "    'loss': [trial['result']['loss'] for trial in trials.trials],\n",
    "})\n",
    "losses = [-trial['result']['loss'] for trial in trials.trials]\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot best loss over time\n",
    "best_losses = [min(losses[:i+1]) for i in range(len(losses))]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(best_losses)), best_losses, marker='o', linestyle='-', color='r')\n",
    "plt.title('Best Loss Over Time')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot evolution of hyperparameters over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['num_epochs'], marker='o', linestyle='-', label='num_epochs')\n",
    "plt.title('Evolution of Epochs')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['learning_rate'], marker='o', linestyle='-', label='learning_rate')\n",
    "plt.title('Evolution of Learning Rate')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of hyperparameters and loss\n",
    "sns.pairplot(results_df, diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Hyperparameters and Loss', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Hyperparameters and Loss')\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameters\n",
    "optimal_num_epochs = best['num_epochs']\n",
    "optimal_learning_rate = best['learning_rate']\n",
    "print(f\"Best num_epochs: {optimal_num_epochs}\")\n",
    "print(f\"Best learning_rate: {optimal_learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model,criterion = train_validation(train_features, test_features, train_target, test_target,name,optimal_num_epochs, optimal_learning_rate)\n",
    "df1 = cross_check(features,target,name,10,optimal_num_epochs, optimal_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Crop']).values\n",
    "target = data['Crop'].values\n",
    "\n",
    "print(\"Random OverSampler\")\n",
    "ROSample = RandomOverSampler(sampling_strategy=\"all\")\n",
    "features,target = ROSample.fit_resample(features,target)\n",
    "\n",
    "resampled_data = pd.DataFrame(features)\n",
    "resampled_data['Crop'] = target\n",
    "limited_data = resampled_data.groupby('Crop', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=1000, random_state=42) if len(x) > 1000 else x\n",
    ").reset_index(drop=True)\n",
    "features = limited_data.drop(columns=['Crop']).values\n",
    "target = limited_data['Crop'].values\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).float().to(\"cuda\")\n",
    "target = torch.tensor(target, dtype=torch.long).long().to(\"cuda\")\n",
    "name = f\"{model_name}_ROS\"\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# pso_history = []\n",
    "# optimal_num_epochs, optimal_learning_rate = pso_optimize(\n",
    "#     train_features, \n",
    "#     test_features, \n",
    "#     train_target, \n",
    "#     test_target, \n",
    "#     lb, \n",
    "#     ub,\n",
    "#     num_particles=10,\n",
    "#     maxiter=10\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('hyperopt.tpe').setLevel(logging.ERROR)\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    verbose=True,\n",
    "    rstate=np.random.default_rng(),\n",
    "    show_progressbar=True,\n",
    "    return_argmin=False,\n",
    ")\n",
    "print(\"Best hyperparameters found:\", best)\n",
    "\n",
    "# Convert trials to a pandas DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame({\n",
    "    'num_epochs': [trial['misc']['vals']['num_epochs'][0] for trial in trials.trials],\n",
    "    'learning_rate': [trial['misc']['vals']['learning_rate'][0] for trial in trials.trials],\n",
    "    'loss': [trial['result']['loss'] for trial in trials.trials],\n",
    "})\n",
    "losses = [-trial['result']['loss'] for trial in trials.trials]\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot best loss over time\n",
    "best_losses = [min(losses[:i+1]) for i in range(len(losses))]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(best_losses)), best_losses, marker='o', linestyle='-', color='r')\n",
    "plt.title('Best Loss Over Time')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot evolution of hyperparameters over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['num_epochs'], marker='o', linestyle='-', label='num_epochs')\n",
    "plt.title('Evolution of Epochs')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['learning_rate'], marker='o', linestyle='-', label='learning_rate')\n",
    "plt.title('Evolution of Learning Rate')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of hyperparameters and loss\n",
    "sns.pairplot(results_df, diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Hyperparameters and Loss', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Hyperparameters and Loss')\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameters\n",
    "optimal_num_epochs = best['num_epochs']\n",
    "optimal_learning_rate = best['learning_rate']\n",
    "print(f\"Best num_epochs: {optimal_num_epochs}\")\n",
    "print(f\"Best learning_rate: {optimal_learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,criterion = train_validation(train_features, test_features, train_target, test_target,name,optimal_num_epochs, optimal_learning_rate)\n",
    "df2 = cross_check(features,target,name,10,optimal_num_epochs, optimal_learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Crop']).values\n",
    "target = data['Crop'].values\n",
    "\n",
    "print(\"Random UnderSampler\")\n",
    "ROSample = RandomUnderSampler(sampling_strategy=\"all\")\n",
    "features,target = ROSample.fit_resample(features,target)\n",
    "\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).float().to(\"cuda\")\n",
    "target = torch.tensor(target, dtype=torch.long).long().to(\"cuda\")\n",
    "name = f\"{model_name}_RUS\"\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# pso_history = []\n",
    "# optimal_num_epochs, optimal_learning_rate = pso_optimize(\n",
    "#     train_features, \n",
    "#     test_features, \n",
    "#     train_target, \n",
    "#     test_target, \n",
    "#     lb, \n",
    "#     ub,\n",
    "#     num_particles=10,\n",
    "#     maxiter=10\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('hyperopt.tpe').setLevel(logging.ERROR)\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    verbose=True,\n",
    "    rstate=np.random.default_rng(),\n",
    "    show_progressbar=True,\n",
    "    return_argmin=False,\n",
    ")\n",
    "print(\"Best hyperparameters found:\", best)\n",
    "\n",
    "# Convert trials to a pandas DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame({\n",
    "    'num_epochs': [trial['misc']['vals']['num_epochs'][0] for trial in trials.trials],\n",
    "    'learning_rate': [trial['misc']['vals']['learning_rate'][0] for trial in trials.trials],\n",
    "    'loss': [trial['result']['loss'] for trial in trials.trials],\n",
    "})\n",
    "losses = [-trial['result']['loss'] for trial in trials.trials]\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot best loss over time\n",
    "best_losses = [min(losses[:i+1]) for i in range(len(losses))]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(best_losses)), best_losses, marker='o', linestyle='-', color='r')\n",
    "plt.title('Best Loss Over Time')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot evolution of hyperparameters over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['num_epochs'], marker='o', linestyle='-', label='num_epochs')\n",
    "plt.title('Evolution of Epochs')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['learning_rate'], marker='o', linestyle='-', label='learning_rate')\n",
    "plt.title('Evolution of Learning Rate')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of hyperparameters and loss\n",
    "sns.pairplot(results_df, diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Hyperparameters and Loss', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Hyperparameters and Loss')\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameters\n",
    "optimal_num_epochs = best['num_epochs']\n",
    "optimal_learning_rate = best['learning_rate']\n",
    "print(f\"Best num_epochs: {optimal_num_epochs}\")\n",
    "print(f\"Best learning_rate: {optimal_learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,criterion = train_validation(train_features, test_features, train_target, test_target,name,optimal_num_epochs, optimal_learning_rate)\n",
    "df3 = cross_check(features,target,name,10,optimal_num_epochs, optimal_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Crop']).values\n",
    "target = data['Crop'].values\n",
    "\n",
    "print(\"SMOTE\")\n",
    "\n",
    "ROSample = SMOTE()\n",
    "features,target = ROSample.fit_resample(features,target)\n",
    "\n",
    "resampled_data = pd.DataFrame(features)\n",
    "resampled_data['Crop'] = target\n",
    "limited_data = resampled_data.groupby('Crop', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=1000, random_state=42) if len(x) > 1000 else x\n",
    ").reset_index(drop=True)\n",
    "features = limited_data.drop(columns=['Crop']).values\n",
    "target = limited_data['Crop'].values\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).float().to(\"cuda\")\n",
    "target = torch.tensor(target, dtype=torch.long).long().to(\"cuda\")\n",
    "name = f\"{model_name}_SMOTE\"\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# pso_history = []\n",
    "# optimal_num_epochs, optimal_learning_rate = pso_optimize(\n",
    "#     train_features, \n",
    "#     test_features, \n",
    "#     train_target, \n",
    "#     test_target, \n",
    "#     lb, \n",
    "#     ub,\n",
    "#     num_particles=10,\n",
    "#     maxiter=10\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('hyperopt.tpe').setLevel(logging.ERROR)\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    verbose=True,\n",
    "    rstate=np.random.default_rng(),\n",
    "    show_progressbar=True,\n",
    "    return_argmin=False,\n",
    ")\n",
    "print(\"Best hyperparameters found:\", best)\n",
    "\n",
    "# Convert trials to a pandas DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame({\n",
    "    'num_epochs': [trial['misc']['vals']['num_epochs'][0] for trial in trials.trials],\n",
    "    'learning_rate': [trial['misc']['vals']['learning_rate'][0] for trial in trials.trials],\n",
    "    'loss': [trial['result']['loss'] for trial in trials.trials],\n",
    "})\n",
    "losses = [-trial['result']['loss'] for trial in trials.trials]\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot best loss over time\n",
    "best_losses = [min(losses[:i+1]) for i in range(len(losses))]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(best_losses)), best_losses, marker='o', linestyle='-', color='r')\n",
    "plt.title('Best Loss Over Time')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot evolution of hyperparameters over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['num_epochs'], marker='o', linestyle='-', label='num_epochs')\n",
    "plt.title('Evolution of Epochs')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['learning_rate'], marker='o', linestyle='-', label='learning_rate')\n",
    "plt.title('Evolution of Learning Rate')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of hyperparameters and loss\n",
    "sns.pairplot(results_df, diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Hyperparameters and Loss', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Hyperparameters and Loss')\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameters\n",
    "optimal_num_epochs = best['num_epochs']\n",
    "optimal_learning_rate = best['learning_rate']\n",
    "print(f\"Best num_epochs: {optimal_num_epochs}\")\n",
    "print(f\"Best learning_rate: {optimal_learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,criterion = train_validation(train_features, test_features, train_target, test_target,name,optimal_num_epochs, optimal_learning_rate)\n",
    "df4 = cross_check(features,target,name,10,optimal_num_epochs, optimal_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Crop']).values\n",
    "target = data['Crop'].values\n",
    "\n",
    "print(\"SMOTE + Tomek\")\n",
    "\n",
    "ROSample = SMOTETomek()\n",
    "features,target = ROSample.fit_resample(features,target)\n",
    "\n",
    "resampled_data = pd.DataFrame(features)\n",
    "resampled_data['Crop'] = target\n",
    "limited_data = resampled_data.groupby('Crop', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=1000, random_state=42) if len(x) > 1000 else x\n",
    ").reset_index(drop=True)\n",
    "features = limited_data.drop(columns=['Crop']).values\n",
    "target = limited_data['Crop'].values\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).float().to(\"cuda\")\n",
    "target = torch.tensor(target, dtype=torch.long).long().to(\"cuda\")\n",
    "name = f\"{model_name}_SMOTETOMEK\"\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# pso_history = []\n",
    "# optimal_num_epochs, optimal_learning_rate = pso_optimize(\n",
    "#     train_features, \n",
    "#     test_features, \n",
    "#     train_target, \n",
    "#     test_target, \n",
    "#     lb, \n",
    "#     ub,\n",
    "#     num_particles=10,\n",
    "#     maxiter=10\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('hyperopt.tpe').setLevel(logging.ERROR)\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    verbose=True,\n",
    "    rstate=np.random.default_rng(),\n",
    "    show_progressbar=True,\n",
    "    return_argmin=False,\n",
    ")\n",
    "print(\"Best hyperparameters found:\", best)\n",
    "\n",
    "# Convert trials to a pandas DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame({\n",
    "    'num_epochs': [trial['misc']['vals']['num_epochs'][0] for trial in trials.trials],\n",
    "    'learning_rate': [trial['misc']['vals']['learning_rate'][0] for trial in trials.trials],\n",
    "    'loss': [trial['result']['loss'] for trial in trials.trials],\n",
    "})\n",
    "losses = [-trial['result']['loss'] for trial in trials.trials]\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot best loss over time\n",
    "best_losses = [min(losses[:i+1]) for i in range(len(losses))]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(best_losses)), best_losses, marker='o', linestyle='-', color='r')\n",
    "plt.title('Best Loss Over Time')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot evolution of hyperparameters over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['num_epochs'], marker='o', linestyle='-', label='num_epochs')\n",
    "plt.title('Evolution of Epochs')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['learning_rate'], marker='o', linestyle='-', label='learning_rate')\n",
    "plt.title('Evolution of Learning Rate')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of hyperparameters and loss\n",
    "sns.pairplot(results_df, diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Hyperparameters and Loss', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Hyperparameters and Loss')\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameters\n",
    "optimal_num_epochs = best['num_epochs']\n",
    "optimal_learning_rate = best['learning_rate']\n",
    "print(f\"Best num_epochs: {optimal_num_epochs}\")\n",
    "print(f\"Best learning_rate: {optimal_learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,criterion = train_validation(train_features, test_features, train_target, test_target,name,optimal_num_epochs, optimal_learning_rate)\n",
    "df5 = cross_check(features,target,name,10,optimal_num_epochs, optimal_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Crop']).values\n",
    "target = data['Crop'].values\n",
    "\n",
    "print(\"SMOTEENN\")\n",
    "\n",
    "ROSample = SMOTEENN()\n",
    "features,target = ROSample.fit_resample(features,target)\n",
    "\n",
    "resampled_data = pd.DataFrame(features)\n",
    "resampled_data['Crop'] = target\n",
    "limited_data = resampled_data.groupby('Crop', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=1000, random_state=42) if len(x) > 1000 else x\n",
    ").reset_index(drop=True)\n",
    "features = limited_data.drop(columns=['Crop']).values\n",
    "target = limited_data['Crop'].values\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).float().to(\"cuda\")\n",
    "target = torch.tensor(target, dtype=torch.long).long().to(\"cuda\")\n",
    "name = f\"{model_name}_SMOTEENN\"\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "# pso_history = []\n",
    "# optimal_num_epochs, optimal_learning_rate = pso_optimize(\n",
    "#     train_features, \n",
    "#     test_features, \n",
    "#     train_target, \n",
    "#     test_target, \n",
    "#     lb, \n",
    "#     ub,\n",
    "#     num_particles=10,\n",
    "#     maxiter=20\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('hyperopt.tpe').setLevel(logging.ERROR)\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials,\n",
    "    verbose=True,\n",
    "    rstate=np.random.default_rng(),\n",
    "    show_progressbar=True,\n",
    "    return_argmin=False,\n",
    ")\n",
    "print(\"Best hyperparameters found:\", best)\n",
    "\n",
    "# Convert trials to a pandas DataFrame for easier manipulation\n",
    "results_df = pd.DataFrame({\n",
    "    'num_epochs': [trial['misc']['vals']['num_epochs'][0] for trial in trials.trials],\n",
    "    'learning_rate': [trial['misc']['vals']['learning_rate'][0] for trial in trials.trials],\n",
    "    'loss': [trial['result']['loss'] for trial in trials.trials],\n",
    "})\n",
    "losses = [-trial['result']['loss'] for trial in trials.trials]\n",
    "# Plot the loss values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(losses)), losses, marker='o', linestyle='-', color='b')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot best loss over time\n",
    "best_losses = [min(losses[:i+1]) for i in range(len(losses))]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(range(len(best_losses)), best_losses, marker='o', linestyle='-', color='r')\n",
    "plt.title('Best Loss Over Time')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Best Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot evolution of hyperparameters over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['num_epochs'], marker='o', linestyle='-', label='num_epochs')\n",
    "plt.title('Evolution of Epochs')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.grid()\n",
    "plt.plot(results_df['learning_rate'], marker='o', linestyle='-', label='learning_rate')\n",
    "plt.title('Evolution of Learning Rate')\n",
    "plt.xlabel('Evaluation Number')\n",
    "plt.ylabel('Hyperparameter Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot of hyperparameters and loss\n",
    "sns.pairplot(results_df, diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Hyperparameters and Loss', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Hyperparameters and Loss')\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameters\n",
    "optimal_num_epochs = best['num_epochs']\n",
    "optimal_learning_rate = best['learning_rate']\n",
    "print(f\"Best num_epochs: {optimal_num_epochs}\")\n",
    "print(f\"Best learning_rate: {optimal_learning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,criterion = train_validation(train_features, test_features, train_target, test_target,name,optimal_num_epochs, optimal_learning_rate)\n",
    "df6 = cross_check(features,target,name,10,optimal_num_epochs, optimal_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(f\"../Results/{model_name}_Initial.csv\",index=False)\n",
    "df2.to_csv(f\"../Results/{model_name}_ROS.csv\",index=False)\n",
    "df3.to_csv(f\"../Results/{model_name}_RUS.csv\",index=False)\n",
    "df4.to_csv(f\"../Results/{model_name}_SMOTE.csv\",index=False)\n",
    "df5.to_csv(f\"../Results/{model_name}_SMOTE+TOMEK.csv\",index=False)\n",
    "df6.to_csv(f\"../Results/{model_name}_SMOTEENN.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
